{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a8785bb8c2204813a599840a41a92b9f",
    "deepnote_cell_height": 81.953125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# 9.11: What makes a character loveable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "78ba903c94af4e84bfefa4c5043d1dd4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3192,
    "execution_start": 1662165673706,
    "output_cleared": true,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this code first or nothing else will work!\n",
    "\n",
    "# This code loads the R packages we will use\n",
    "library(coursekata)\n",
    "\n",
    "# This allows our jupyter notebook to print out data frames with a lot of variables (e.g., 40)\n",
    "options(repr.matrix.max.cols=40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc61f255610540a09a82f77fe26e7f01",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## 1.0: Explore the Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "264933d623ec4714a445d044beaa4773",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Let's get familiar with the larger data set we will be working with. Run the code below to take a look at a few characters (one character is represented in each row). \n",
    "\n",
    "**1.1, Think Aloud:** Note anything interesting to you, or that you are curious about, or anything you think we might want to know about the data frame, the characters, or the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "98b029f43e914e8694cf43d00e62b1e8",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Loads the data frame from a google sheet\n",
    "characters <- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vSQ9NRrJDB_KNWNXtApbLGAC_e0C216iG6uSEGPruj2hTCiyYuC8KbtHbrR1OYt9-qxZfDZMaNt0WGW/pub?gid=0&single=true&output=csv\")\n",
    "\n",
    "# Prints out a sample of 5 rows of this data frame\n",
    "sample(characters, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "babcaf33724e475a8e0d10bd7b422f34",
    "deepnote_cell_height": 1469.78125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### The Dataset\n",
    "\n",
    "**Description:** The `characters` data frame contains characters from various fictional universes. At [Open Psychometrics](https://openpsychometrics.org/tests/characters/), more than 3 million volunteers from the internet rated these characters on various traits by using a sliding scale. For example, the character Mushu (from Disney's Mulan), is depicted below being rated on a scale from zero, rude, to 100, respectful. These ratings have been averaged to produce the data frame `characters`.\n",
    "\n",
    "<img src=\"https://i.postimg.cc/tXVg4SjZ/rating-characters.png\" alt=\"example of how people rated a character with a slider\" width = 40%>\n",
    "\n",
    "##### Variable Descriptions\n",
    "\n",
    "- `char_id` The character ID.\n",
    "- `char_name` The character's name.\t\n",
    "- `uni_id` The universe ID for the book, game, movie, or TV show.\n",
    "- `uni_name` The universe name of the book, game, movie, or TV show.\n",
    "- `gender` The gender of the character (M=Male, F=Female, NB=NonBinary).\n",
    "\n",
    "\n",
    "- `abstract` A rating of how abstract (vs concrete) the character is on a scale of 0-100 (0-concrete, 100-abstract).\n",
    "- `agreeable` A rating of how agreeable (vs stubborn) the character is on a scale of 0-100 (0-stubborn, 100-agreeable).\t\n",
    "- `anxious` A rating of how anxious (vs calm) the character is on a scale of 0-100 (0-calm, 100-anxious).\n",
    "- `attractive` A rating of how attractive (vs repulsive) the character is on a scale of 0-100 (0-repulsive, 100-attractive).\t\n",
    "- `beautiful` A rating of how beautiful (vs ugly) the character is on a scale of 0-100 (0-ugly, 100-beautiful).\t\n",
    "- `chaotic` A rating of how chaotic (vs orderly) the character is on a scale of 0-100 (0-orderly, 100-chaotic).\n",
    "- `chill` A rating of how chill (vs offended) the character is on a scale of 0-100 (0-offended, 100-chill).\t\n",
    "- `cool` A rating of how cool (vs dorky) the character is on a scale of 0-100 (0-dorky, 100-cool).\t\n",
    "- `decisive` A rating of how decisive (vs hesitant) the character is on a scale of 0-100 (0-hesitant, 100-decisive).\t\n",
    "- `emotional` A rating of how emotional (vs unemotional) the character is on a scale of 0-100 (0-unemotional, 100-emotional).\t\n",
    "- `extrovert` A rating of how extroverted (vs introverted) the character is on a scale of 0-100 (0-introvert, 100-extrovert).\t\n",
    "- `feminine` A rating of how feminine (vs masculine) the character is on a scale of 0-100 (0-masculine, 100-feminine).\t\n",
    "- `future_focused` A rating of how future-focused (vs present-focused) the character is on a scale of 0-100 (0-present-focused, 100-future-focused).\t\n",
    "- `loveable` A rating of how loveable (vs punchable) the character is on a scale of 0-100 (0-punchable, 100-loveable).\n",
    "- `messy` A rating of how messy (vs neat) the character is on a scale of 0-100 (0-neat, 100-messy).\t\t\n",
    "- `moody` A rating of how moody (vs stable) the character is on a scale of 0-100 (0-stable, 100-moody).\t\t\n",
    "- `open_minded` A rating of how open-minded (vs close-minded) the character is on a scale of 0-100 (0-close-minded, 100-open-minded).\n",
    "- `reasoned` A rating of how reasoned (vs instinctual) the character is on a scale of 0-100 (0-instinctual, 100-reasoned).\n",
    "- `respectful` A rating of how respectful (vs rude) the character is on a scale of 0-100 (0-rude, 100-respectful).\n",
    "- `self_assured` A rating of how self-assured (vs self-conscious) the character is on a scale of 0-100 (0-self-conscious, 100-self-assured).\n",
    "- `self_disciplined` A rating of how self-disciplined (vs disorganized) the character is on a scale of 0-100 (0-disorganized, 100-self-disciplined).\t\n",
    "- `tall` A rating of how tall (vs short) the character is on a scale of 0-100 (0-short, 100-tall).\t\n",
    "- `trusting` A rating of how trusting (vs suspicious) the character is on a scale of 0-100 (0-suspicious, 100-trusting).\n",
    "\n",
    "\n",
    "##### Data Source: \n",
    "\n",
    "Originally collected at [Open Psychometrics](https://openpsychometrics.org/tests/characters/) made available by Tanya Shapiro as a [Tidy Tuesday data set](https://github.com/rfordatascience/tidytuesday/tree/master/data/2022/2022-08-16)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f520fc1fbd024b1dbb3fe95dd756a774",
    "deepnote_cell_height": 61.953125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## 2.0: Generate Questions/Hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1f19eb85a6ca4919a0c49f0a3ce09263",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**2.1:** The code below `arranges` the data frame in ascending order, from least `respectful` (i.e., rude) to most `respectful`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e36ff2a2a9e445219bfb10230bbea3b1",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "arrange(characters, respectful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f2726c13b1414ea4b0ee78e5ed63da4a",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**2.2:** Modify the code above so we can see the least/most loveable characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "cf6a2a049cb84fd5ad1636d24d19f1d0",
    "deepnote_cell_height": 62.421875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## 3.0: Good vs. Bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4989d22b09664cb28095eda3eada383c",
    "deepnote_cell_height": 361.265625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**3.1:** We are going to compare the characteristics between good characters and bad characters to see which one(s) might do a better job helping us predict which group a character belongs in. \n",
    "\n",
    "**From Hypothesis to Word Equation (the proto-model).** We would translate a hypothesis (e.g., characters that are more lovable as more likely to be good rather than bad) into a word equation like this: **good_bad = loveable + other stuff**.\n",
    "\n",
    "Come up with a few hypotheses and express them as word equations below:\n",
    "\n",
    "1. e.g., characters that are more lovable will be rated as good: **good_bad = loveable + other stuff**\n",
    "2. Write your own.\n",
    "3. \n",
    "4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "990566c5853841988a8ae4f23ab9ccb3",
    "deepnote_cell_height": 110.75,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Explore Word Equations with Data Visualizations\n",
    "\n",
    "**3.2:** We've set you up with some code to look at these theories in a visualization. Describe what kind of patterns you see. Does one model (i.e., word equation) appear to explain more variation than the others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "f718d19013784c0e8afa8e4797ab2476",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1218,
    "execution_start": 1662167426649,
    "output_cleared": true,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example code to explore an example hypothesis: \n",
    "# good_bad = loveable + other stuff\n",
    "gf_point(good_bad ~ loveable, data = characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "0bb824f139614e4c98b01c03f70d57f6",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# modify this code with the idea you'd like to explore\n",
    "gf_point(good_bad ~ loveable, data = characters, color = \"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "513ca03759cc4e19b493741417902d04",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Totally extra but if you'd like to see a list of all the colors available in R, this is a famous R color cheatsheet (you can always google \"Rcolor\" and get it too): http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "eb5aa10b3c0b4f91abff03aad0154d53",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## 4.0 - Everybody Loves a Baddie!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "093a0c3fa9f549d79d938b7730b7fc9d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**4.1:** Are we sure that good characters are really more loved than bad ones?  OR could there be some other explination for what we see ...like coincidence? How could we even tell?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2:** The first step: we need an average loveable rating for both the good group and the bad group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this block to get the average loveability for both groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3:** How big is the difference between the groups?  What would we expect to see if there wasn't really a difference between good and bad (if both groups where equaly loved)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.4:** What explanation(s) do we have for how big this gap between the group averages is?\n",
    "\n",
    "- Reason 1:\n",
    "- Reason 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.5:** Could this difference be a coincidence?  How likely would it be to get a gap like this between the groups if there really was no difference between good and bad characters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run some code to simulate the results if there was no \n",
    "# difference between good and bad characters' loveability:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.6:** If we did this many times, what would happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have the computer do it over and over 1000s of times!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.7:** Look at the results.  Still think it could have been coincidence? "
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "4299b82fb0b442afba493be98592e118",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  },
  "nbsimplegrader": {
   "publish_config": {
    "classes": [],
    "options": [],
    "tools": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
